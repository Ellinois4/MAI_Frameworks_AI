{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8e0af8",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2  \n",
    "## Проведение исследований с логистической и линейной регрессией\n",
    "\n",
    "В работе исследуются:\n",
    "- **логистическая регрессия** для задачи классификации;\n",
    "- **линейная регрессия** для задачи регрессии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13b039",
   "metadata": {},
   "source": [
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b63d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    root_mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.metrics import make_scorer\n",
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda092f",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и разбиение выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc80d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к данным\n",
    "LOAN_PATH = os.path.join(\"data\", \"Loan_approval_data_2025.csv\")\n",
    "SONG_PATH = os.path.join(\"data\", \"song_data.csv\")\n",
    "\n",
    "# Загрузка датасетов\n",
    "loan_df = pd.read_csv(LOAN_PATH)\n",
    "song_df = pd.read_csv(SONG_PATH)\n",
    "\n",
    "# Одобрение кредита\n",
    "y_cls = loan_df[\"loan_status\"]\n",
    "X_cls = loan_df.drop(columns=[\"loan_status\", \"customer_id\"])\n",
    "\n",
    "cat_cols_cls = X_cls.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_cls = X_cls.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=RANDOM_STATE, stratify=y_cls\n",
    ")\n",
    "\n",
    "# Популярность песни\n",
    "y_reg = song_df[\"song_popularity\"]\n",
    "X_reg = song_df.drop(columns=[\"song_popularity\", \"song_name\"])\n",
    "\n",
    "cat_cols_reg = X_reg.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_reg = X_reg.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2eb02",
   "metadata": {},
   "source": [
    "## 2. Бейзлайн моделей\n",
    "\n",
    "Формируем бейзлайн для задач классификации и регрессии с использованием линейных моделей и пайплайнов предобработки данных. Для числовых признаков выполняется заполнение пропусков и масштабирование, а для категориальных — заполнение пропусков и one-hot кодирование. Предобработка объединяется с моделью в единый пайплайн, что обеспечивает корректную обработку данных при обучении и тестировании.\n",
    "\n",
    "Для классификации используется логистическая регрессия, для регрессии — линейная регрессия. После обучения моделей вычисляются стандартные метрики качества, которые служат отправной точкой для последующего сравнения с улучшенными моделями.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16f03222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн (классификация): {'accuracy': 0.8652, 'precision': 0.8709619846510798, 'recall': 0.8864668483197093, 'f1': 0.8786460208858481, 'roc_auc': np.float64(0.9445712917471123)}\n",
      "Бейзлайн (регрессия):     {'rmse': 21.48576103236179, 'mae': 17.055369122574042, 'r2': 0.04239734907577464}\n"
     ]
    }
   ],
   "source": [
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess_cls = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols_cls),\n",
    "    (\"cat\", categorical_pipe, cat_cols_cls)\n",
    "])\n",
    "\n",
    "preprocess_reg = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols_reg),\n",
    "    (\"cat\", categorical_pipe, cat_cols_reg)\n",
    "])\n",
    "\n",
    "baseline_cls = Pipeline([\n",
    "    (\"prep\", preprocess_cls),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "baseline_reg = Pipeline([\n",
    "    (\"prep\", preprocess_reg),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "baseline_cls.fit(Xc_train, yc_train)\n",
    "baseline_reg.fit(Xr_train, yr_train)\n",
    "\n",
    "yc_pred = baseline_cls.predict(Xc_test)\n",
    "yc_proba = baseline_cls.predict_proba(Xc_test)[:, 1]\n",
    "yr_pred = baseline_reg.predict(Xr_test)\n",
    "\n",
    "baseline_cls_res = {\n",
    "    \"accuracy\": accuracy_score(yc_test, yc_pred),\n",
    "    \"precision\": precision_score(yc_test, yc_pred, zero_division=0),\n",
    "    \"recall\": recall_score(yc_test, yc_pred, zero_division=0),\n",
    "    \"f1\": f1_score(yc_test, yc_pred, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(yc_test, yc_proba)\n",
    "}\n",
    "\n",
    "baseline_reg_res = {\n",
    "    \"rmse\": root_mean_squared_error(yr_test, yr_pred),\n",
    "    \"mae\": mean_absolute_error(yr_test, yr_pred),\n",
    "    \"r2\": r2_score(yr_test, yr_pred)\n",
    "}\n",
    "\n",
    "print(\"Бейзлайн (классификация):\", baseline_cls_res)\n",
    "print(\"Бейзлайн (регрессия):    \", baseline_reg_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab6122",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "В части классификации подбираем параметр регуляризации `C` для логистической регрессии. Используется `GridSearchCV` с кросс-валидацией `StratifiedKFold`, что позволяет сохранить баланс классов в разбиениях. Качество моделей оценивается по метрике ROC-AUC. После выбора лучшей модели рассчитываются основные метрики классификации на тестовой выборке.\n",
    "\n",
    "В части регрессии рассматриваются две регуляризованные линейные модели — Ridge и Lasso. Для обеих моделей выполняется подбор параметра регуляризации `alpha` с использованием кросс-валидации `KFold`. В качестве критерия качества используется RMSE. После обучения выбирается модель с наилучшим значением метрики на кросс-валидации и оценивается её качество на тестовой выборке по метрикам RMSE, MAE и R².\n",
    "\n",
    "Таким образом, данный код реализует этап улучшения моделей за счёт настройки гиперпараметров и позволяет сравнить полученные результаты с бейзлайном.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da45420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры (классификация): {'model__C': 10} | CV ROC-AUC: 0.9460661149993392\n",
      "Улучшенная (классификация): {'accuracy': 0.8653, 'precision': 0.8711174580506962, 'recall': 0.8864668483197093, 'f1': 0.8787251282974701, 'roc_auc': np.float64(0.9445407400896545)}\n",
      "Лучший регрессор: Lasso\n",
      "Лучшие параметры (регрессия): {'model__alpha': 0.01} | CV -RMSE: -21.387719777963973\n",
      "Улучшенная (регрессия):     {'rmse': 21.485203664412715, 'mae': 17.054866331327474, 'r2': 0.04244703129106686}\n"
     ]
    }
   ],
   "source": [
    "# --- Логистическая регрессия: подбор C ---\n",
    "param_grid_cls = {\"model__C\": [0.01, 0.1, 1, 10]}\n",
    "\n",
    "tuned_cls = Pipeline([\n",
    "    (\"prep\", preprocess_cls),\n",
    "    (\"model\", LogisticRegression(max_iter=3000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_cls = GridSearchCV(\n",
    "    tuned_cls,\n",
    "    param_grid_cls,\n",
    "    cv=cv_cls,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=1  # важно: на macOS часто убирает матричные RuntimeWarning\n",
    ")\n",
    "\n",
    "gs_cls.fit(Xc_train, yc_train)\n",
    "best_cls = gs_cls.best_estimator_\n",
    "\n",
    "print(\"Лучшие параметры (классификация):\", gs_cls.best_params_, \"| CV ROC-AUC:\", gs_cls.best_score_)\n",
    "\n",
    "yc_pred2 = best_cls.predict(Xc_test)\n",
    "yc_proba2 = best_cls.predict_proba(Xc_test)[:, 1]\n",
    "\n",
    "improved_cls_res = {\n",
    "    \"accuracy\": accuracy_score(yc_test, yc_pred2),\n",
    "    \"precision\": precision_score(yc_test, yc_pred2, zero_division=0),\n",
    "    \"recall\": recall_score(yc_test, yc_pred2, zero_division=0),\n",
    "    \"f1\": f1_score(yc_test, yc_pred2, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(yc_test, yc_proba2),\n",
    "}\n",
    "\n",
    "print(\"Улучшенная (классификация):\", improved_cls_res)\n",
    "\n",
    "# --- Регрессия: Ridge и Lasso (подбор alpha) ---\n",
    "param_grid_reg = {\"model__alpha\": [0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_reg),\n",
    "    (\"model\", Ridge())\n",
    "])\n",
    "\n",
    "lasso_pipe = Pipeline([\n",
    "    (\"prep\", preprocess_reg),\n",
    "    (\"model\", Lasso(max_iter=10000))\n",
    "])\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs_ridge = GridSearchCV(ridge_pipe, param_grid_reg, cv=cv_reg, scoring=rmse_scorer, n_jobs=1)\n",
    "gs_lasso = GridSearchCV(lasso_pipe, param_grid_reg, cv=cv_reg, scoring=rmse_scorer, n_jobs=1)\n",
    "\n",
    "gs_ridge.fit(Xr_train, yr_train)\n",
    "gs_lasso.fit(Xr_train, yr_train)\n",
    "\n",
    "use_ridge = gs_ridge.best_score_ > gs_lasso.best_score_\n",
    "best_reg = gs_ridge.best_estimator_ if use_ridge else gs_lasso.best_estimator_\n",
    "\n",
    "print(\"Лучший регрессор:\", \"Ridge\" if use_ridge else \"Lasso\")\n",
    "print(\"Лучшие параметры (регрессия):\",\n",
    "      (gs_ridge.best_params_ if use_ridge else gs_lasso.best_params_),\n",
    "      \"| CV -RMSE:\", (gs_ridge.best_score_ if use_ridge else gs_lasso.best_score_))\n",
    "\n",
    "yr_pred2 = best_reg.predict(Xr_test)\n",
    "\n",
    "improved_reg_res = {\n",
    "    \"rmse\": root_mean_squared_error(yr_test, yr_pred2),\n",
    "    \"mae\": mean_absolute_error(yr_test, yr_pred2),\n",
    "    \"r2\": r2_score(yr_test, yr_pred2),\n",
    "}\n",
    "\n",
    "print(\"Улучшенная (регрессия):    \", improved_reg_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9d28b-fad2-4308-b641-0191995e3107",
   "metadata": {},
   "source": [
    "## 4. Подготовка матриц для своих моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51ed6d10-6340-4456-8387-ffa30939616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS shapes: (40000, 27) (10000, 27) | sparse: False\n",
      "REG shapes: (15068, 13) (3767, 13)\n"
     ]
    }
   ],
   "source": [
    "# сигмоида\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -50, 50)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "# --- Классификация: loan_status ---\n",
    "Xc_train_tr = preprocess_cls.fit_transform(Xc_train)\n",
    "Xc_test_tr  = preprocess_cls.transform(Xc_test)\n",
    "\n",
    "# y в numpy\n",
    "yc_train_np = np.asarray(yc_train).astype(int)\n",
    "yc_test_np  = np.asarray(yc_test).astype(int)\n",
    "\n",
    "print(\"CLS shapes:\", Xc_train_tr.shape, Xc_test_tr.shape, \"| sparse:\", sparse.issparse(Xc_train_tr))\n",
    "\n",
    "# --- Регрессия: song_popularity ---\n",
    "Xr_train_tr = preprocess_reg.fit_transform(Xr_train)\n",
    "Xr_test_tr  = preprocess_reg.transform(Xr_test)\n",
    "\n",
    "yr_train_np = np.asarray(yr_train).astype(float)\n",
    "yr_test_np  = np.asarray(yr_test).astype(float)\n",
    "\n",
    "# для OLS удобнее плотный формат (здесь обычно немного признаков)\n",
    "Xr_train_arr = Xr_train_tr.toarray() if sparse.issparse(Xr_train_tr) else np.asarray(Xr_train_tr)\n",
    "Xr_test_arr  = Xr_test_tr.toarray()  if sparse.issparse(Xr_test_tr)  else np.asarray(Xr_test_tr)\n",
    "\n",
    "print(\"REG shapes:\", Xr_train_arr.shape, Xr_test_arr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cd9cd-de8a-48e9-872d-214cc0543ebf",
   "metadata": {},
   "source": [
    "## 5. Имплементация линейной регрессии (OLS) + Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d91a5101-e087-46bb-82d7-72fa91ef6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinearRegression and MyRidgeRegression defined.\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        # добавляем столбец единиц под свободный член\n",
    "        Xb = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        # OLS через псевдообратную (устойчивее, чем явная (X^T X)^-1)\n",
    "        w = np.linalg.pinv(Xb) @ y\n",
    "\n",
    "        self.intercept_ = w[0]\n",
    "        self.coef_ = w[1:]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return self.intercept_ + X @ self.coef_\n",
    "\n",
    "\n",
    "class MyRidgeRegression:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = float(alpha)\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        Xb = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        n_features = Xb.shape[1]\n",
    "\n",
    "        # Ridge: (X^T X + alpha*I)^-1 X^T y\n",
    "        I = np.eye(n_features)\n",
    "        I[0, 0] = 0.0  # свободный член не регуляризуем\n",
    "        w = np.linalg.solve(Xb.T @ Xb + self.alpha * I, Xb.T @ y)\n",
    "\n",
    "        self.intercept_ = w[0]\n",
    "        self.coef_ = w[1:]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return self.intercept_ + X @ self.coef_\n",
    "\n",
    "print(\"MyLinearRegression and MyRidgeRegression defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c356343-ff1b-48c3-bf79-6edd210d3152",
   "metadata": {},
   "source": [
    "## 6. Обучение/оценка самописной регрессии + сравнение с sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "284d2de5-e74e-454a-9a6c-1cb4dd2bcd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My OLS (regression) baseline: {'rmse': 21.48576103236179, 'mae': 17.055369122574042, 'r2': 0.04239734907577464}\n",
      "My Ridge (regression) improved: {'rmse': 21.48576096510958, 'mae': 17.055369062279855, 'r2': 0.04239735507052533}\n",
      "alpha used: 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# --- baseline: OLS ---\n",
    "my_lin = MyLinearRegression().fit(Xr_train_arr, yr_train_np)\n",
    "yr_pred_my = my_lin.predict(Xr_test_arr)\n",
    "\n",
    "my_reg_baseline_res = {\n",
    "    \"rmse\": root_mean_squared_error(yr_test_np, yr_pred_my),\n",
    "    \"mae\": mean_absolute_error(yr_test_np, yr_pred_my),\n",
    "    \"r2\": r2_score(yr_test_np, yr_pred_my)\n",
    "}\n",
    "print(\"My OLS (regression) baseline:\", my_reg_baseline_res)\n",
    "\n",
    "# --- improved: Ridge (берём alpha из лучшей модели, если она есть) ---\n",
    "alpha_best = 1.0\n",
    "if \"best_reg\" in globals():\n",
    "    # если best_reg - это sklearn Ridge/Lasso, пытаемся достать alpha\n",
    "    try:\n",
    "        alpha_best = float(best_reg.named_steps[\"model\"].alpha)\n",
    "    except Exception:\n",
    "        alpha_best = 1.0\n",
    "\n",
    "my_ridge = MyRidgeRegression(alpha=alpha_best).fit(Xr_train_arr, yr_train_np)\n",
    "yr_pred_my2 = my_ridge.predict(Xr_test_arr)\n",
    "\n",
    "my_reg_improved_res = {\n",
    "    \"rmse\": root_mean_squared_error(yr_test_np, yr_pred_my2),\n",
    "    \"mae\": mean_absolute_error(yr_test_np, yr_pred_my2),\n",
    "    \"r2\": r2_score(yr_test_np, yr_pred_my2)\n",
    "}\n",
    "print(\"My Ridge (regression) improved:\", my_reg_improved_res)\n",
    "print(\"alpha used:\", alpha_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae554c7-08d4-4f07-844c-0ef5a804726c",
   "metadata": {},
   "source": [
    "## 7. Имплементация логистической регрессии (SGD, работает со sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2bedd95-6209-41b8-8034-e38a9657c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLogisticRegressionSGD defined.\n"
     ]
    }
   ],
   "source": [
    "class MyLogisticRegressionSGD:\n",
    "    def __init__(self, lr=0.1, epochs=15, batch_size=2048, l2=0.0, random_state=42):\n",
    "        self.lr = float(lr)\n",
    "        self.epochs = int(epochs)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.l2 = float(l2)\n",
    "        self.random_state = int(random_state)\n",
    "\n",
    "        self.w_ = None\n",
    "        self.b_ = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y).astype(float)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        self.w_ = np.zeros(n_features, dtype=float)\n",
    "        self.b_ = 0.0\n",
    "\n",
    "        idx_all = np.arange(n_samples)\n",
    "\n",
    "        for ep in range(self.epochs):\n",
    "            rng.shuffle(idx_all)\n",
    "\n",
    "            for start in range(0, n_samples, self.batch_size):\n",
    "                batch_idx = idx_all[start:start+self.batch_size]\n",
    "                Xb = X[batch_idx]\n",
    "                yb = y[batch_idx]\n",
    "\n",
    "                # z = Xw + b\n",
    "                z = Xb.dot(self.w_) + self.b_\n",
    "                p = sigmoid(z)\n",
    "\n",
    "                # градиенты\n",
    "                err = (p - yb)  # (m,)\n",
    "                grad_w = (Xb.T.dot(err)) / len(batch_idx)\n",
    "                grad_b = float(np.mean(err))\n",
    "\n",
    "                # L2 регуляризация (как в ridge)\n",
    "                if self.l2 > 0:\n",
    "                    grad_w += self.l2 * self.w_\n",
    "\n",
    "                # шаг\n",
    "                self.w_ -= self.lr * grad_w\n",
    "                self.b_ -= self.lr * grad_b\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        z = X.dot(self.w_) + self.b_\n",
    "        p1 = sigmoid(z)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.vstack([p0, p1]).T\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X)[:, 1] >= threshold).astype(int)\n",
    "\n",
    "print(\"MyLogisticRegressionSGD defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd2731-d285-42a4-92a6-8cf8ef39809c",
   "metadata": {},
   "source": [
    "## 8. Обучение/оценка самописной классификации + улучшение с регуляризацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c478ec60-be74-4cb9-ba54-384e176a0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Logistic (classification) baseline: {'accuracy': 0.8545, 'precision': 0.8552631578947368, 'recall': 0.885558583106267, 'f1': 0.8701472556894244, 'roc_auc': np.float64(0.9347557231316661)}\n",
      "My Logistic (classification) improved: {'accuracy': 0.8424, 'precision': 0.8348389296062724, 'recall': 0.8897366030881018, 'f1': 0.8614139992965177, 'roc_auc': np.float64(0.9259236269181926)}\n",
      "C_best: 10.0 | l2 used: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- baseline: без регуляризации ---\n",
    "my_log_base = MyLogisticRegressionSGD(lr=0.1, epochs=15, batch_size=2048, l2=0.0, random_state=RANDOM_STATE)\n",
    "my_log_base.fit(Xc_train_tr, yc_train_np)\n",
    "\n",
    "yc_pred_my = my_log_base.predict(Xc_test_tr)\n",
    "yc_proba_my = my_log_base.predict_proba(Xc_test_tr)[:, 1]\n",
    "\n",
    "my_cls_baseline_res = {\n",
    "    \"accuracy\": accuracy_score(yc_test_np, yc_pred_my),\n",
    "    \"precision\": precision_score(yc_test_np, yc_pred_my, zero_division=0),\n",
    "    \"recall\": recall_score(yc_test_np, yc_pred_my, zero_division=0),\n",
    "    \"f1\": f1_score(yc_test_np, yc_pred_my, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(yc_test_np, yc_proba_my),\n",
    "}\n",
    "print(\"My Logistic (classification) baseline:\", my_cls_baseline_res)\n",
    "\n",
    "# --- improved: добавляем L2 как в улучшенном бейзлайне (через лучший C, если он есть) ---\n",
    "# связь простая: чем больше C, тем меньше регуляризация => l2 ~ 1/C\n",
    "C_best = 1.0\n",
    "if \"gs_cls\" in globals():\n",
    "    try:\n",
    "        C_best = float(gs_cls.best_params_[\"model__C\"])\n",
    "    except Exception:\n",
    "        C_best = 1.0\n",
    "\n",
    "l2_used = 1.0 / C_best\n",
    "\n",
    "my_log_imp = MyLogisticRegressionSGD(lr=0.05, epochs=25, batch_size=2048, l2=l2_used, random_state=RANDOM_STATE)\n",
    "my_log_imp.fit(Xc_train_tr, yc_train_np)\n",
    "\n",
    "yc_pred_my2 = my_log_imp.predict(Xc_test_tr)\n",
    "yc_proba_my2 = my_log_imp.predict_proba(Xc_test_tr)[:, 1]\n",
    "\n",
    "my_cls_improved_res = {\n",
    "    \"accuracy\": accuracy_score(yc_test_np, yc_pred_my2),\n",
    "    \"precision\": precision_score(yc_test_np, yc_pred_my2, zero_division=0),\n",
    "    \"recall\": recall_score(yc_test_np, yc_pred_my2, zero_division=0),\n",
    "    \"f1\": f1_score(yc_test_np, yc_pred_my2, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(yc_test_np, yc_proba_my2),\n",
    "}\n",
    "print(\"My Logistic (classification) improved:\", my_cls_improved_res)\n",
    "print(\"C_best:\", C_best, \"| l2 used:\", l2_used)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e917267",
   "metadata": {},
   "source": [
    "## 9. Сравнение и выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fca5e6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sk_baseline</th>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.870962</td>\n",
       "      <td>0.886467</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.944571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk_improved</th>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.871117</td>\n",
       "      <td>0.886467</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.944541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_baseline</th>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.870147</td>\n",
       "      <td>0.934756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_improved</th>\n",
       "      <td>0.8424</td>\n",
       "      <td>0.834839</td>\n",
       "      <td>0.889737</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>0.925924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  precision    recall        f1   roc_auc\n",
       "sk_baseline    0.8652   0.870962  0.886467  0.878646  0.944571\n",
       "sk_improved    0.8653   0.871117  0.886467  0.878725  0.944541\n",
       "my_baseline    0.8545   0.855263  0.885559  0.870147  0.934756\n",
       "my_improved    0.8424   0.834839  0.889737  0.861414  0.925924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sk_baseline</th>\n",
       "      <td>21.485761</td>\n",
       "      <td>17.055369</td>\n",
       "      <td>0.042397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk_improved</th>\n",
       "      <td>21.485204</td>\n",
       "      <td>17.054866</td>\n",
       "      <td>0.042447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_baseline</th>\n",
       "      <td>21.485761</td>\n",
       "      <td>17.055369</td>\n",
       "      <td>0.042397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_improved</th>\n",
       "      <td>21.485761</td>\n",
       "      <td>17.055369</td>\n",
       "      <td>0.042397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rmse        mae        r2\n",
       "sk_baseline  21.485761  17.055369  0.042397\n",
       "sk_improved  21.485204  17.054866  0.042447\n",
       "my_baseline  21.485761  17.055369  0.042397\n",
       "my_improved  21.485761  17.055369  0.042397"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_compare = pd.DataFrame(\n",
    "    [\n",
    "        baseline_cls_res,\n",
    "        improved_cls_res,\n",
    "        my_cls_baseline_res,\n",
    "        my_cls_improved_res\n",
    "    ],\n",
    "    index=[\"sk_baseline\", \"sk_improved\", \"my_baseline\", \"my_improved\"]\n",
    ")\n",
    "\n",
    "reg_compare = pd.DataFrame(\n",
    "    [\n",
    "        baseline_reg_res,\n",
    "        improved_reg_res,\n",
    "        my_reg_baseline_res,\n",
    "        my_reg_improved_res\n",
    "    ],\n",
    "    index=[\"sk_baseline\", \"sk_improved\", \"my_baseline\", \"my_improved\"]\n",
    ")\n",
    "\n",
    "display(cls_compare)\n",
    "display(reg_compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc18eb-fb15-4b23-bd86-c5d73145da6a",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "В задаче классификации библиотечные модели логистической регрессии из `sklearn` показали наилучшие результаты. Подбор гиперпараметров дал лишь небольшое улучшение качества, что говорит о стабильности бейзлайна. Самописная реализация работает корректно, однако по всем основным метрикам уступает библиотечной версии, а её улучшение не привело к росту качества.\n",
    "\n",
    "В задаче регрессии различия между бейзлайном и улучшенными моделями практически отсутствуют. Значения RMSE, MAE и R² совпадают для библиотечных и самописных реализаций, что подтверждает корректность моей имплементации линейной регрессии, но также указывает на ограниченные возможности линейных моделей для данного набора данных.\n",
    "\n",
    "В целом библиотечные реализации обеспечивают более стабильное качество и удобны для практического применения, тогда как самописные модели целесообразно использовать в учебных целях для понимания работы алгоритмов.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
